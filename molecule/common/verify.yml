---
- name: Verify OS configuration
  hosts: rke2_server:rke2_agent
  any_errors_fatal: true
  vars:
    _multipath_service: multipathd.service
  tasks:
    - name: Query service facts
      ansible.builtin.service_facts:

    - name: Check multipath service
      ansible.builtin.assert:
        that: _multipath_service in services

    - name: Check multipath service status
      ansible.builtin.assert:
        that:
          - _service.state == _stopped
          - _service.status == _masked
        fail_msg: "Expected service state {{ _stopped }} and status {{ _masked }}. Got {{ _service.state }}, {{ _service.status }}"
      vars:
        _service: "{{ services[_multipath_service] }}"
        _stopped: "stopped"
        _masked: "masked"

    - name: Verify multipath service mask
      block:
        - name: Attempt multipath service start
          ansible.builtin.command: >-
            systemctl start {{ _multipath_service }}
          register: _multipath_start
          ignore_errors: true
          become: true

        - name: Verify service mask
          ansible.builtin.assert:
            that:
              - _multipath_start is failed
              - _multipath_start.stderr | regex_search('.* ' + _multipath_service + ' is masked.')
            fail_msg: "Got service start error {{ _multipath_start.stderr }}"

    - name: Verify swap is disabled
      ansible.builtin.assert:
        that: ansible_swaptotal_mb == 0
        fail_msg: "Swap is enabled with {{ ansible_swaptotal_mb }}MB"

    - name: Query nofile soft limits
      ansible.builtin.shell:
        cmd: "ulimit -Sn"
      register: _nofile_limit
      changed_when: false

    - name: Verify nofile soft limits
      ansible.builtin.assert:
        that: _value == _expected
        fail_msg: "nofile soft limit is set to {{ _value }}, expected {{ _expected }}"
      vars:
        _value: "{{ _nofile_limit.stdout | int }}"
        _expected: "{{ _rke2_limits_nofile | int }}"

    - name: Query nofile hard limits
      ansible.builtin.shell:
        cmd: "ulimit -Hn"
      register: _nofile_hard_limit
      changed_when: false

    - name: Verify nofile hard limits
      ansible.builtin.assert:
        that: _value == _expected
        fail_msg: "nofile hard limit is set to {{ _value }}, expected {{ _expected }}"
      vars:
        _value: "{{ _nofile_hard_limit.stdout | int }}"
        _expected: "{{ _rke2_limits_nofile | int }}"

    - name: Query inotify max_user_instances
      ansible.builtin.sysctl:
        name: fs.inotify.max_user_instances
      register: _inotify_max_user_instances
      changed_when: false

    - name: Verify inotify max_user_instances
      ansible.builtin.assert:
        that: _value == _expected
        fail_msg: "fs.inotify.max_user_instances is set to {{ _value }}, expected {{ _expected }}"
      vars:
        _value: "{{ _inotify_max_user_instances.value | int }}"
        _expected: "{{ _rke2_sysctl_inotify_max_user_instances | int }}"

    - name: Query inotify max_user_watches
      ansible.builtin.sysctl:
        name: fs.inotify.max_user_watches
      register: _inotify_max_user_watches
      changed_when: false

    - name: Verify inotify max_user_watches
      ansible.builtin.assert:
        that: _value == _expected
        fail_msg: "fs.inotify.max_user_watches is set to {{ _value }}, expected {{ _expected }}"
      vars:
        _value: "{{ _inotify_max_user_watches.value | int }}"
        _expected: "{{ _rke2_sysctl_inotify_max_user_watches | int }}"

    - name: Query inotify max_queued_events
      ansible.builtin.sysctl:
        name: fs.inotify.max_queued_events
      register: _inotify_max_queued_events
      changed_when: false

    - name: Verify inotify max_queued_events
      ansible.builtin.assert:
        that: _value == _expected
        fail_msg: "fs.inotify.max_queued_events is set to {{ _value }}, expected {{ _expected }}"
      vars:
        _value: "{{ _inotify_max_queued_events.value | int }}"
        _expected: "{{ _rke2_sysctl_inotify_max_queued_events | int }}"

- name: Verify RKE2 install
  hosts: rke2_server
  any_errors_fatal: true
  vars:
    _servers: "{{ groups['rke2_server'] }}"
    _agents: "{{ groups['rke2_agent'] }}"
    _members: "{{ _servers + _agents }}"
    _retry: 20
    _delay: 30
  tasks:
    - name: Install jq
      ansible.builtin.package:
        name: jq
      become: true

    - name: Slurp kubeconfig cluster file
      ansible.builtin.slurp:
        src: /etc/rancher/rke2/rke2.yaml
      register: _kubeconfig_slurp
      become: true

    - name: Verify kubeconfig cluster api configuration
      ansible.builtin.assert:
        that: _kubeconfig_server == _kubeconfig_server_expected
        fail_msg: "Failed cluster API verification, expected {{ _kubeconfig_server_expected }}, got {{ _kubeconfig_server }}"
      vars:
        _kubeconfig_content: "{{ _kubeconfig_slurp['content'] | b64decode | ansible.builtin.from_yaml }}"
        _kubeconfig_server: "{{ _kubeconfig_content.clusters[0].cluster.server }}"
        _kubeconfig_server_expected: "https://127.0.0.1:6443"

    - name: Slurp kubeconfig cluster file
      ansible.builtin.slurp:
        src: "~/.kube/config"
      register: _kubeconfig_slurp

    - name: Verify kubeconfig user api configuration
      ansible.builtin.assert:
        that: _kubeconfig_server == _kubeconfig_server_expected
        fail_msg: "Failed cluster API verification, expected {{ _kubeconfig_server_expected }}, got {{ _kubeconfig_server }}"
      vars:
        _kubeconfig_content: "{{ _kubeconfig_slurp['content'] | b64decode | ansible.builtin.from_yaml }}"
        _kubeconfig_server: "{{ _kubeconfig_content.clusters[0].cluster.server }}"
        _kubeconfig_server_expected: "https://api.rke2.pokerops.net:6443"

    - name: Query cluster nodes
      ansible.builtin.shell:
        cmd: "/var/lib//rancher/rke2/bin/kubectl get node -o name | cut -d'/' -f2"
        executable: /bin/bash
      register: _kubectl_nodes
      changed_when: false

    - name: Set cluster facts
      ansible.builtin.set_fact:
        _nodes: "{{ _kubectl_nodes.stdout_lines }}"

    - name: Debug cluster nodes
      debug:
        var: _nodes

    - name: Debug cluster members
      debug:
        var: _members

    - name: Verify cluster nodes
      block:
        - name: Check cluster node status
          ansible.builtin.assert:
            that: _members | difference(_nodes) | length == 0

      rescue:
        - name: Debug unregistered nodes
          ansible.builtin.debug:
            msg: "Nodes [{{ ', '.join(_members | difference(_nodes)) }}] are not registered to the cluster"

        - name: Fail cluster node check
          ansible.builtin.fail:

    - name: Query cluster status
      ansible.builtin.shell:
        cmd: "kubectl get cs -o json | jq '.items | map(.conditions | map(.type) | .[])'"
        executable: /bin/bash
      register: _kubectl_status
      changed_when: false

    - name: Check cluster status
      ansible.builtin.assert:
        that: _kubectl_status.stdout | reject('equalto', 'Healthy') | length == 0

    - name: Validate cluster components
      when: rke2_component_check | default(True) | bool
      run_once: true
      block:
        - name: Set kubeconfig facts
          ansible.builtin.set_fact:
            _config_path: "{{ molecule_local_kubeconfig }}"

        - name: Validate secret namespaces
          ansible.builtin.assert:
            that: ns_missing | length == 0
            fail_msg: "The following namespaces are missing from deployed secrets [{{ ns_missing | join(', ') }}]"
          vars:
            ns_query: "{{ query('kubernetes.core.k8s', kind='Namespace', kubeconfig=_config_path) }}"
            ns_names: "{{ ns_query | map(attribute='metadata.name') }}"
            ns_targets: "{{ rke2_secrets | default([]) | map(attribute='namespace') }}"
            ns_missing: "{{ ns_targets | difference(ns_names) }}"

        - name: Validate secret namespace status
          ansible.builtin.assert:
            that: ns_failed | length == 0
            fail_msg: "The following namespaces are in failed status [{{ ns_failed | join(', ') }}]"
          vars:
            ns_query: "{{ query('kubernetes.core.k8s', kind='Namespace', kubeconfig=_config_path) }}"
            ns_inactive: "{{ ns_query | rejectattr('status.phase', 'equalto', 'Active') }}"
            ns_failed: "{{ ns_inactive | map(attribute='metadata.name') }}"

        - name: Validate secret list
          ansible.builtin.assert:
            that: secret_missing | length == 0
            fail_msg: "The following secrets are missing from secret definitions [{{ secret_missing | join(', ') }}]"
          vars:
            secret_query: "{{ query('kubernetes.core.k8s', kind='Secret', kubeconfig=_config_path) }}"
            secret_names: "{{ secret_query | map(attribute='metadata.name') }}"
            secret_targets: "{{ rke2_secrets | default([]) | map(attribute='name') }}"
            secret_missing: "{{ secret_targets | difference(secret_names) }}"

        - name: Validate cluster-issuers
          block:
            - name: Validate cluster-issuer status
              ansible.builtin.fail:
                msg: "Found cluster issuers with failed status"
              vars:
                issuers_status: "{{ issuers_query | selectattr('status', 'defined') | map(attribute='status') | flatten }}"
                issuers_conditions: "{{ issuers_status | selectattr('conditions', 'defined') | map(attribute='conditions') | flatten }}"
                issuers_ready: "{{ issuers_conditions | selectattr('type', 'equalto', 'Ready') }}"
                issuers_failed: "{{ issuers_ready | rejectattr('status', 'equalto', 'True') }}"
                issuers_query: "{{ query('kubernetes.core.k8s', kind='ClusterIssuer', kubeconfig=_config_path) }}"
              retries: "{{ _retry }}"
              delay: "{{ _delay }}"
              until: issuers_failed | length == 0
              failed_when: issuers_failed | length > 0

          always:
            - name: Debug cluster-issuers
              ansible.builtin.debug:
                var: issuers_query
              vars:
                issuers_query: "{{ query('kubernetes.core.k8s', kind='ClusterIssuer', kubeconfig=_config_path) }}"

        - name: Verify cluster pod status
          block:
            - name: Verify cluster pod status
              ansible.builtin.shell:
                cmd: "/var/lib//rancher/rke2/bin/kubectl get pod -o json | jq '.items'"
              register: _argocd_pod_data
              retries: "{{ _retry }}"
              delay: "{{ _delay }}"
              vars:
                _pod_data: "{{ _argocd_pod_data.stdout | from_json }}"
                _pod_status: "{{ _pod_data | selectattr('status', 'defined') }}"
                _pod_phase: "{{ _pod_status | selectattr('status.phase', 'defined') }}"
                _pod_completed: "{{ _pod_phase | rejectattr('status.phase', 'equalto', 'Running') }}"
                _pod_failed: "{{ _pod_completed | rejectattr('status.phase', 'equalto', 'Succeeded') }}"
              until: _pod_failed | length == 0
              failed_when:
                - (_pod_status | length) != (_pod_data | length)
                - (_pod_phase | length) != (_pod_data | length)
                - _pod_failed | length > 0
              changed_when: false

          rescue:
            - name: Debug failed cluster pods
              ansible.builtin.fail:
                msg: "The following pods are in failed status [{{ _pod_names | join(', ') }}]"
              vars:
                _pod_data: "{{ _argocd_pod_data.stdout | from_json }}"
                _pod_unhealthy: "{{ _pod_data['items'] | rejectattr('status.health.status', 'equalto', 'Healthy') }}"
                _pod_outofsync: "{{ _pod_unhealthy | rejectattr('status.sync.status', 'equalto', 'Synced') }}"
                _pod_failed: "{{ _pod_unhealthy + _pod_outofsync }}"
                _pod_names: "{{ _pod_failed | map(attribute='metadata.name') }}"

        - name: Verify cluster job status
          block:
            - name: Verify cluster job status
              ansible.builtin.shell:
                cmd: "/var/lib//rancher/rke2/bin/kubectl get job -o json | jq '.items'"
              register: _argocd_job_data
              retries: "{{ _retry }}"
              delay: "{{ _delay }}"
              vars:
                _job_data: "{{ _argocd_job_data.stdout | from_json }}"
                _job_status: "{{ _job_data | selectattr('status', 'defined') }}"
                _job_success: "{{ _job_status | selectattr('status.succeeded', 'defined') }}"
                _job_failed: "{{ _job_success | rejectattr('status.succeeded', 'equalto', 1) }}"
              until: _job_failed | length == 0
              failed_when:
                - (_job_status | length) != (_job_data | length)
                - (_job_phase | length) != (_job_data | length)
                - _job_failed | length > 0
              changed_when: false

          rescue:
            - name: Debug failed cluster jobs
              ansible.builtin.fail:
                msg: "The following jobs are in failed status [{{ _job_names | join(', ') }}]"
              vars:
                _job_data: "{{ _argocd_job_data.stdout | from_json }}"
                _job_unhealthy: "{{ _job_data['items'] | rejectattr('status.health.status', 'equalto', 'Healthy') }}"
                _job_outofsync: "{{ _job_unhealthy | rejectattr('status.sync.status', 'equalto', 'Synced') }}"
                _job_failed: "{{ _job_unhealthy + _job_outofsync }}"
                _job_names: "{{ _job_failed | map(attribute='metadata.name') }}"

        - name: Set test facts
          ansible.builtin.set_fact:
            _volume_test_namespace: longhorn-test
            _volume_test_name: longhorn-test
            _volume_test_mount: longhorn-test

        - name: Create test namespace
          kubernetes.core.k8s:
            state: present
            kubeconfig: "{{ _config_path }}"
            resource_definition:
              apiVersion: v1
              kind: Namespace
              metadata:
                name: longhorn-test
          delegate_to: localhost

        - name: Create test volume claim
          kubernetes.core.k8s:
            state: present
            kubeconfig: "{{ _config_path }}"
            resource_definition:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: longhorn-test
                namespace: longhorn-test
              spec:
                storageClassName: longhorn
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 3Gi
          delegate_to: localhost

        - name: Create volume consumer
          kubernetes.core.k8s:
            state: present
            kubeconfig: "{{ _config_path }}"
            resource_definition:
              apiVersion: v1
              kind: Pod
              metadata:
                name: longhorn-test
                namespace: longhorn-test
              spec:
                volumes:
                  - persistentVolumeClaim:
                      claimName: longhorn-test
                    name: longhorn-test
                containers:
                  - name: longhorn-test-container
                    image: nginx
                    ports:
                      - containerPort: 80
                        name: "http-server"
                    volumeMounts:
                      - mountPath: "/usr/share/nginx/html"
                        name: longhorn-test
          delegate_to: localhost

        - name: Verify persistent claim status
          block:
            - name: Verify persistent claim status
              ansible.builtin.shell:
                cmd: "/var/lib//rancher/rke2/bin/kubectl get pvc -o json | jq '.items'"
              register: _argocd_pvc_data
              retries: "{{ _retry }}"
              delay: "{{ _delay }}"
              vars:
                _pvc_data: "{{ _argocd_pvc_data.stdout | from_json }}"
                _pvc_status: "{{ _pvc_data | selectattr('status', 'defined') }}"
                _pvc_success: "{{ _pvc_status | selectattr('status.succeeded', 'defined') }}"
                _pvc_failed: "{{ _pvc_success | rejectattr('status.succeeded', 'equalto', 1) }}"
              until: _pvc_failed | length == 0
              failed_when:
                - (_pvc_status | length) != (_pvc_data | length)
                - (_pvc_phase | length) != (_pvc_data | length)
                - _pvc_failed | length > 0
              changed_when: false

          rescue:
            - name: Debug failed cluster persistent claims
              ansible.builtin.fail:
                msg: "The following persistent claims are in failed status [{{ _job_names | join(', ') }}]"
              vars:
                _job_data: "{{ _argocd_job_data.stdout | from_json }}"
                _job_unhealthy: "{{ _job_data['items'] | rejectattr('status.health.status', 'equalto', 'Healthy') }}"
                _job_outofsync: "{{ _job_unhealthy | rejectattr('status.sync.status', 'equalto', 'Synced') }}"
                _job_failed: "{{ _job_unhealthy + _job_outofsync }}"
                _job_names: "{{ _job_failed | map(attribute='metadata.name') }}"

        - name: Verify persistent claims
          block:
            - name: Validate persistent claim status
              ansible.builtin.fail:
                msg: "The following pvcs are in failed status [{{ pvc_names | join(', ') }}]"
              vars:
                pvc_names: "{{ pvc_failed | map(attribute='metadata.name') }}"
                pvc_failed: "{{ pvc_query | rejectattr('status.phase', 'equalto', 'Bound') }}"
                pvc_query: "{{ query('kubernetes.core.k8s', kind='PersistentVolumeClaim', kubeconfig=_config_path) }}"
              retries: "{{ _retry }}"
              delay: "{{ _delay }}"
              until: pvc_failed | length == 0
              failed_when: pvc_failed | length > 0

          always:
            - name: Debug persistent claim status
              ansible.builtin.debug:
                var: pvc_query
              vars:
                pvc_query: "{{ query('kubernetes.core.k8s', kind='PersistentVolumeClaim', kubeconfig=_config_path) }}"

        - name: Query argocd reposerver deployment
          kubernetes.core.k8s_info:
            kind: Deployment
            name: argocd-repo-server
            namespace: argocd
            kubeconfig: "{{ _config_path }}"
          register: _deployment_query
          retries: "{{ _retry }}"
          delay: "{{ _delay }}"
          until: _deployment_query.resources | length > 0
          delegate_to: localhost

        - name: Set argocd deployment env facts
          ansible.builtin.set_fact:
            _argocd_env_exec_item: "{{ _reposerver_env_exec_item }}"
          vars:
            _reposerver_def: "{{ _deployment_query.resources[0] }}"
            _reposerver_env: "{{ _reposerver_def.spec.template.spec.containers[0].env }}"
            _reposerver_env_exec_item: "{{ _reposerver_env | selectattr('name', 'equalto', 'ARGOCD_EXEC_TIMEOUT') }}"

        - name: Check argocd exec timeout parameter
          ansible.builtin.assert:
            that: _argocd_env_exec_item | length > 0
            fail_msg: "env var ARGOCD_EXEC_TIMEOUT is not set"

        - name: Check argocd exec timeout value
          ansible.builtin.assert:
            that: _argocd_env_exec_value == "3m"
            fail_msg: "env var ARGOCD_EXEC_TIMEOUT is not set correctly ({{ _argocd_env_exec_value }})"
          vars:
            _argocd_env_exec_value: "{{ _argocd_env_exec_item[0].value }}"

        - name: Verify argocd application status
          block:
            - name: Verify argocd application status
              ansible.builtin.shell:
                cmd: /var/lib//rancher/rke2/bin/kubectl get applications -n argocd -o json
              register: _argocd_app_data
              retries: "{{ _retry }}"
              delay: "{{ _delay }}"
              vars:
                _app_data: "{{ _argocd_app_data.stdout | from_json }}"
                _app_unhealthy: "{{ _app_data['items'] | rejectattr('status.health.status', 'equalto', 'Healthy') }}"
                _app_outofsync: "{{ _app_unhealthy | rejectattr('status.sync.status', 'equalto', 'Synced') }}"
                _app_failed: "{{ _app_unhealthy + _app_outofsync }}"
              until:
                - _app_data | length > 0
                - _app_failed | length == 0
              no_log: true

            - name: Debug argocd applications
              ansible.builtin.debug:
                msg: "The following argocd applications have been deployed successfully [{{ _app_success | unique | join(', ') }}]"
              vars:
                _app_data: "{{ _argocd_app_data.stdout | from_json }}"
                _app_healthy: "{{ _app_data['items'] | selectattr('status.health.status', 'equalto', 'Healthy') }}"
                _app_sync: "{{ _app_healthy | selectattr('status.sync.status', 'equalto', 'Synced') }}"
                _app_success: "{{ _app_sync | map(attribute='metadata.name') }}"

          rescue:
            - name: Debug failed applications
              ansible.builtin.fail:
                msg: "The following argocd applications are in failed status [{{ _app_names | unique | join(', ') }}]"
              vars:
                _app_data: "{{ _argocd_app_data.stdout | from_json }}"
                _app_unhealthy: "{{ _app_data['items'] | rejectattr('status.health.status', 'equalto', 'Healthy') }}"
                _app_outofsync: "{{ _app_unhealthy | rejectattr('status.sync.status', 'equalto', 'Synced') }}"
                _app_failed: "{{ _app_unhealthy + _app_outofsync }}"
                _app_names: "{{ _app_failed | map(attribute='metadata.name') }}"

          always:
            - name: Debug cluster status location
              ansible.builtin.debug:
                msg: "Cluster application status data saved to {{ molecule_logdir }}/cluster_applications.json"

            - name: Create logdir
              ansible.builtin.file:
                path: "{{ molecule_logdir }}"
                state: directory
                owner: root
                group: root
                mode: "u=rwx,go=rx"
              run_once: true

            - name: Debug cluster status
              ansible.builtin.copy:
                content: "{{ _argocd_app_data.stdout | from_json | to_nice_json }}"
                dest: "{{ molecule_logdir }}/cluster_applications.json"
              delegate_to: localhost

- name: Verify RKE2 cluster update status
  hosts: rke2_server:rke2_agent
  any_errors_fatal: true
  tasks:
    - name: Verify node update count
      ansible.builtin.command: apt list --upgradable | grep -v ^Listing | wc -l
      become: true
      changed_when: false
      register: _update_query
      failed_when: _update_query.stdout | int > 0
      when: rke2_update_check | default(False) | bool
