---
- name: Verify multipath deactivation
  hosts: rke2_server:rke2_agent
  any_errors_fatal: true
  vars:
    _multipath_service: multipathd.service
  tasks:
    - name: Query service facts
      ansible.builtin.service_facts:

    - name: Check multipath service
      ansible.builtin.assert:
        that: _multipath_service in services

    - name: Check multipath service status
      ansible.builtin.assert:
        that:
          - _service.state == _stopped
          - _service.status == _masked
        fail_msg: "Expected service state {{ _stopped }} and status {{ _masked }}. Got {{ _service.state }}, {{ _service.status }}"
      vars:
        _service: "{{ services[_multipath_service] }}"
        _stopped: "stopped"
        _masked: "masked"

    - name: Verify multipath service mask
      block:
        - name: Attempt multipath service start
          ansible.builtin.command: >-
            systemctl start {{ _multipath_service }}
          register: _multipath_start
          ignore_errors: true
          become: true

        - name: Verify service mask
          ansible.builtin.assert:
            that:
              - _multipath_start is failed
              - _multipath_start.stderr | regex_search('.* ' + _multipath_service + ' is masked.')
            fail_msg: "Got service start error {{ _multipath_start.stderr }}"

- name: Verify RKE2 install
  hosts: rke2_server
  any_errors_fatal: true
  vars:
    _servers: "{{ groups['rke2_server'] }}"
    _agents: "{{ groups['rke2_agent'] }}"
    _members: "{{ _servers + _agents }}"
    _retry: 6
    _delay: 20
  tasks:
    - name: Install JQ
      ansible.builtin.package:
        name: jq
      become: true

    - name: Slurp kubeconfig cluster file
      ansible.builtin.slurp:
        src: /etc/rancher/rke2/rke2.yaml
      register: _kubeconfig_slurp
      become: true

    - name: Verify kubeconfig cluster api configuration
      ansible.builtin.assert:
        that: _kubeconfig_server == _kubeconfig_server_expected
        fail_msg: "Failed cluster API verification, expected {{ _kubeconfig_server_expected }}, got {{ _kubeconfig_server }}"
      vars:
        _kubeconfig_content: "{{ _kubeconfig_slurp['content'] | b64decode | ansible.builtin.from_yaml }}"
        _kubeconfig_server: "{{ _kubeconfig_content.clusters[0].cluster.server }}"
        _kubeconfig_server_expected: "https://127.0.0.1:6443"

    - name: Slurp kubeconfig cluster file
      ansible.builtin.slurp:
        src: "~/.kube/config"
      register: _kubeconfig_slurp

    - name: Verify kubeconfig user api configuration
      ansible.builtin.assert:
        that: _kubeconfig_server == _kubeconfig_server_expected
        fail_msg: "Failed cluster API verification, expected {{ _kubeconfig_server_expected }}, got {{ _kubeconfig_server }}"
      vars:
        _kubeconfig_content: "{{ _kubeconfig_slurp['content'] | b64decode | ansible.builtin.from_yaml }}"
        _kubeconfig_server: "{{ _kubeconfig_content.clusters[0].cluster.server }}"
        _kubeconfig_server_expected: "https://api.rke2.pokerops.net:6443"

    - name: Query cluster nodes
      ansible.builtin.shell:
        cmd: "/var/lib//rancher/rke2/bin/kubectl get node -o name | cut -d'/' -f2"
        executable: /bin/bash
      register: _kubectl_nodes
      changed_when: false

    - name: Set cluster facts
      ansible.builtin.set_fact:
        _nodes: "{{ _kubectl_nodes.stdout_lines }}"

    - name: Debug cluster nodes
      debug:
        var: _nodes

    - name: Debug cluster members
      debug:
        var: _members

    - name: Verify cluster nodes
      block:
        - name: Check cluster node status
          ansible.builtin.assert:
            that: _members | difference(_nodes) | length == 0

      rescue:
        - name: Debug unregistered nodes
          ansible.builtin.debug:
            msg: "Nodes [{{ ', '.join(_members | difference(_nodes)) }}] are not registered to the cluster"

        - name: Fail cluster node check
          ansible.builtin.fail:

    - name: Query cluster status
      ansible.builtin.shell:
        cmd: "kubectl get cs -o json | jq '.items | map(.conditions | map(.type) | .[])'"
        executable: /bin/bash
      register: _kubectl_status
      changed_when: false

    - name: Check cluster status
      ansible.builtin.assert:
        that: _kubectl_status.stdout | reject('equalto', 'Healthy') | length == 0

    - name: Validate cluster components
      when: rke2_component_check | default(True) | bool
      run_once: true
      block:
        - name: Create local tempdir
          ansible.builtin.tempfile:
            state: directory
            suffix: kubeconfig
          register: _tempdir
          delegate_to: localhost
          changed_when: false

        - name: Set kubeconfig facts
          ansible.builtin.set_fact:
            _config_path: "{{ _tempdir.path }}/config.yaml"
            _config_data: "{{ _config_raw | combine(_config_override) | to_nice_json(indent=2) }}"
          vars:
            _config_raw: "{{ _kubeconfig_slurp['content'] | b64decode | from_yaml }}"
            _config_cluster: "{{ _config_raw.clusters[0] }}"
            _config_override:
              clusters:
                - name: "{{ _config_cluster.name }}"
                  cluster:
                    server: "https://{{ ansible_default_ipv4.address }}:6443"
                    certificate-authority-data: "{{ _config_cluster.cluster['certificate-authority-data'] }}"

        - name: Copy kubeconfig to local tempdir
          ansible.builtin.copy:
            dest: "{{ _config_path }}"
            content: "{{ _config_data }}"
            mode: "u=rw,go=r"
          delegate_to: localhost
          changed_when: false

        - name: Validate secret namespaces
          ansible.builtin.assert:
            that: ns_missing | length == 0
            fail_msg: "the following namespaces are missing from deployed secrets [{{ ns_missing | join(', ') }}]"
          vars:
            ns_query: "{{ query('kubernetes.core.k8s', kind='Namespace', kubeconfig=_config_path) }}"
            ns_names: "{{ ns_query | map(attribute='metadata.name') }}"
            ns_targets: "{{ rke2_secrets | default([]) | map(attribute='namespace') }}"
            ns_missing: "{{ ns_targets | difference(ns_names) }}"

        - name: Validate secret namespace status
          ansible.builtin.assert:
            that: ns_failed | length == 0
            fail_msg: "the following namespaces are in failed status [{{ ns_failed | join(', ') }}]"
          vars:
            ns_query: "{{ query('kubernetes.core.k8s', kind='Namespace', kubeconfig=_config_path) }}"
            ns_inactive: "{{ ns_query | rejectattr('status.phase', 'equalto', 'Active') }}"
            ns_failed: "{{ ns_inactive | map(attribute='metadata.name') }}"

        - name: Validate secret list
          ansible.builtin.assert:
            that: secret_missing | length == 0
            fail_msg: "the following secrets are missing from secret definitions [{{ secret_missing | join(', ') }}]"
          vars:
            secret_query: "{{ query('kubernetes.core.k8s', kind='Secret', kubeconfig=_config_path) }}"
            secret_names: "{{ secret_query | map(attribute='metadata.name') }}"
            secret_targets: "{{ rke2_secrets | default([]) | map(attribute='name') }}"
            secret_missing: "{{ secret_targets | difference(secret_names) }}"

        - name: Validate pod status
          ansible.builtin.fail:
            msg: "the following pods are in failed status [{{ pods_failed | map(attribute='metadata.name') | join(', ') }}]"
          vars:
            pods_status: "{{ pods_query | selectattr('status', 'defined') }}"
            pods_phase: "{{ pods_status | selectattr('status.phase', 'defined') }}"
            pods_completed: "{{ pods_phase | rejectattr('status.phase', 'equalto', 'Running') }}"
            pods_failed: "{{ pods_completed | rejectattr('status.phase', 'equalto', 'Succeeded') }}"
            pods_query: "{{ query('kubernetes.core.k8s', kind='Pod', kubeconfig=_config_path) }}"
          retries: "{{ _retry }}"
          delay: "{{ _delay }}"
          until: pods_failed | length == 0
          failed_when:
            - (pods_status | length) != (pods_query | length)
            - (pods_phase | length) != (pods_query | length)
            - pods_failed | length > 0

        - name: Validate job status
          ansible.builtin.fail:
            msg: "the following jobs are in failed status [{{ jobs_failed | map(attribute='metadata.name') | join(', ') }}]"
          vars:
            jobs_status: "{{ jobs_query | selectattr('status', 'defined') }}"
            jobs_success: "{{ jobs_status | selectattr('status.succeeded', 'defined') }}"
            jobs_failed: "{{ jobs_success | rejectattr('status.succeeded', 'equalto', 1) }}"
            jobs_query: "{{ query('kubernetes.core.k8s', kind='Job', kubeconfig=_config_path) }}"
          retries: "{{ _retry }}"
          delay: "{{ _delay }}"
          until: jobs_failed | length == 0
          failed_when:
            - (jobs_status | length) != (jobs_query | length)
            - (jobs_phase | length) != (jobs_query | length)
            - jobs_failed | length > 0

        - name: Set test facts
          ansible.builtin.set_fact:
            _volume_test_namespace: longhorn-test
            _volume_test_name: longhorn-test
            _volume_test_mount: longhorn-test

        - name: Create test namespace
          kubernetes.core.k8s:
            state: present
            kubeconfig: "{{ _config_path }}"
            resource_definition:
              apiVersion: v1
              kind: Namespace
              metadata:
                name: longhorn-test
          delegate_to: localhost

        - name: Create test volume claim
          kubernetes.core.k8s:
            state: present
            kubeconfig: "{{ _config_path }}"
            resource_definition:
              apiVersion: v1
              kind: PersistentVolumeClaim
              metadata:
                name: longhorn-test
                namespace: longhorn-test
              spec:
                storageClassName: longhorn
                accessModes:
                  - ReadWriteOnce
                resources:
                  requests:
                    storage: 3Gi
          delegate_to: localhost

        - name: Create volume consumer
          kubernetes.core.k8s:
            state: present
            kubeconfig: "{{ _config_path }}"
            resource_definition:
              apiVersion: v1
              kind: Pod
              metadata:
                name: longhorn-test
                namespace: longhorn-test
              spec:
                volumes:
                  - persistentVolumeClaim:
                      claimName: longhorn-test
                    name: longhorn-test
                containers:
                  - name: longhorn-test-container
                    image: nginx
                    ports:
                      - containerPort: 80
                        name: "http-server"
                    volumeMounts:
                      - mountPath: "/usr/share/nginx/html"
                        name: longhorn-test
          delegate_to: localhost

        - name: Verify persistent claims
          block:
            - name: Validate persistent claim status
              ansible.builtin.fail:
                msg: "the following pvcs are in failed status [{{ pvc_names | join(', ') }}]"
              vars:
                pvc_names: "{{ pvc_failed | map(attribute='metadata.name') }}"
                pvc_failed: "{{ pvc_query | rejectattr('status.phase', 'equalto', 'Bound') }}"
                pvc_query: "{{ query('kubernetes.core.k8s', kind='PersistentVolumeClaim', kubeconfig=_config_path) }}"
              retries: "{{ _retry }}"
              delay: "{{ _delay }}"
              until: pvc_failed | length == 0
              failed_when: pvc_failed | length > 0

          always:
            - name: Debug persistent claim status
              ansible.builtin.debug:
                var: pvc_query
              vars:
                pvc_query: "{{ query('kubernetes.core.k8s', kind='PersistentVolumeClaim', kubeconfig=_config_path) }}"

        - name: Query argocd ingress metadata
          kubernetes.core.k8s_info:
            kind: Ingress
            name: argocd-server
            namespace: argocd
            kubeconfig: "{{ _config_path }}"
          vars:
            _ip: ip
            _ingress: ingress
          register: _ingress_query
          retries: "{{ _retry }}"
          delay: "{{ _delay }}"
          until:
            - _ingress_query.resources | length > 0
            - _ingress in _ingress_query.resources[0].status.loadBalancer
            - _ingress_query.resources[0].status.loadBalancer.ingress | length > 0
            - _ip in _ingress_query.resources[0].status.loadBalancer.ingress[0]
          delegate_to: localhost

        - name: Set argocd ingress facts
          ansible.builtin.set_fact:
            ingress_argocd_ip: "{{ _ingress_query.resources[0].status.loadBalancer.ingress[0].ip }}"

        - name: Verify argocd health status
          ansible.builtin.command:
            cmd: "curl -sLk https://argocd.{{ rke2_cluster_name }}/healthz --resolve argocd.{{ rke2_cluster_name }}:443:{{ ingress_argocd_ip }} --fail"
          delegate_to: localhost
          register: _argocd_health_check
          retries: "{{ _retry }}"
          delay: "{{ _delay }}"
          until: _argocd_health_check is succeeded
          changed_when: false

        - name: Query argocd reposerver deployment
          kubernetes.core.k8s_info:
            kind: Deployment
            name: argocd-repo-server
            namespace: argocd
            kubeconfig: "{{ _config_path }}"
          register: _deployment_query
          retries: "{{ _retry }}"
          delay: "{{ _delay }}"
          until: _deployment_query.resources | length > 0
          delegate_to: localhost

        - name: Set argocd deployment env facts
          ansible.builtin.set_fact:
            _argocd_env_exec_item: "{{ _reposerver_env_exec_item }}"
          vars:
            _reposerver_def: "{{ _deployment_query.resources[0] }}"
            _reposerver_env: "{{ _reposerver_def.spec.template.spec.containers[0].env }}"
            _reposerver_env_exec_item: "{{ _reposerver_env | selectattr('name', 'equalto', 'ARGOCD_EXEC_TIMEOUT') }}"

        - name: Check argocd exec timeout parameter
          ansible.builtin.assert:
            that: _argocd_env_exec_item | length > 0
            fail_msg: "env var ARGOCD_EXEC_TIMEOUT is not set"

        - name: Check argocd exec timeout value
          ansible.builtin.assert:
            that: _argocd_env_exec_value == "3m"
            fail_msg: "env var ARGOCD_EXEC_TIMEOUT is not set correctly ({{ _argocd_env_exec_value }})"
          vars:
            _argocd_env_exec_value: "{{ _argocd_env_exec_item[0].value }}"

        - name: Query argocd access secret
          kubernetes.core.k8s_info:
            kind: Secret
            name: argocd-initial-admin-secret
            namespace: argocd
            kubeconfig: "{{ _config_path }}"
          register: _argocd_secret_query
          retries: "{{ _retry }}"
          delay: "{{ _delay }}"
          until: _argocd_secret_query.resources | length > 0
          delegate_to: localhost

        - name: Auth against argocd api
          ansible.builtin.command:
            cmd: >
              curl -sLk -XPOST https://argocd.{{ rke2_cluster_name }}/api/v1/session
                --resolve argocd.{{ rke2_cluster_name }}:443:{{ ingress_argocd_ip }}
                --header "Content-Type: application/json"
                --data '{ "username": "{{ _argocd_admin_username }}", "password": "{{ _argocd_admin_password }}" }'
          vars:
            _argocd_admin_username: "admin"
            _argocd_admin_password: "{{ _argocd_admin_data.data.password | b64decode }}"
            _argocd_admin_data: "{{ _argocd_secret_query.resources[0] }}"
          register: argocd_auth_data
          delegate_to: localhost

        - name: Record argocd auth token
          ansible.builtin.set_fact:
            argocd_admin_token: "{{ _argocd_auth_data.token }}"
          vars:
            _argocd_auth_data: "{{ argocd_auth_data.stdout | from_json }}"

        - name: Verify argocd application status
          block:
            - name: Query argocd application status
              ansible.builtin.uri:
                url: "https://{{ ingress_argocd_ip }}/api/v1/applications?refresh=true"
                headers:
                  host: "argocd.{{ rke2_cluster_name }}"
                  cookie: "argocd.token={{ argocd_admin_token }}"
                validate_certs: false
              retries: "{{ _retry }}"
              delay: "{{ _delay }}"
              register: _argocd_app_data
              vars:
                _app_data: "{{ _argocd_app_data.json['items'] }}"
                _app_failed: "{{ _app_data | rejectattr('status.health.status', 'equalto', 'Healthy') }}"
              until: _app_failed | length == 0

          rescue:
            - name: Debug failed applications
              ansible.builtin.fail:
                msg: "the following argocd applications are in failed status [{{ _app_names | join(', ') }}]"
              vars:
                _app_data: "{{ argocd_app_data.json['items'] }}"
                _app_failed: "{{ _app_data | rejectattr('status.health.status', 'equalto', 'Healthy') }}"
                _app_names: "{{ _app_failed | map(attribute='metadata.name') }}"

      always:
        - name: Remove local tempdir
          ansible.builtin.file:
            path: "{{ _tempdir.path }}"
            state: absent
          changed_when: false

- name: Verify RKE2 cluster update status
  hosts: rke2_server:rke2_agent
  any_errors_fatal: true
  tasks:
    - name: Verify node update count
      ansible.builtin.command: apt list --upgradable | grep -v ^Listing | wc -l
      become: true
      changed_when: false
      register: _update_query
      failed_when: _update_query.stdout | int > 0
      when: rke2_update_check | default(False) | bool
